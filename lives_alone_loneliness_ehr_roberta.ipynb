{"cells":[{"cell_type":"code","execution_count":null,"id":"88915680-0b37-4a68-8a44-34853941ab46","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14339,"status":"ok","timestamp":1728261602553,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"88915680-0b37-4a68-8a44-34853941ab46","outputId":"03d1de55-2ecc-41ee-dfc4-576a2eb4d1b2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["!pip install transformers\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report, confusion_matrix\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n","\n","import torch\n","torch.cuda.empty_cache()\n","import seaborn as sns\n","import transformers\n","import json\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import RobertaModel, RobertaTokenizer\n","import logging\n","logging.basicConfig(level=logging.ERROR)\n","import seaborn as sn\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from google.colab import output\n","\n","#GPU usage setup\n","from torch import cuda\n","device = 'cuda' if cuda.is_available() else 'cpu'\n","import random\n","random.seed(1)\n","np.random.seed(1)\n","torch.cuda.manual_seed(1)\n","torch.manual_seed(1)\n","import time\n","start_time = time.time()"]},{"cell_type":"code","execution_count":null,"id":"5m1ALKezEpD8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":82475,"status":"ok","timestamp":1728261685024,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"5m1ALKezEpD8","outputId":"17f708e6-936d-4962-ee2c-8c0426f16199"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive/\n","/content/gdrive/MyDrive/LonelinessR21\n"," annotation_Drew_sample_social_disconnection.xlsx\n"," annotation_Drew_sample_stigmatizing_labels.xlsx\n"," annotation_Selen_sample_social_disconnection.xlsx\n"," annotation_Selen_sample_stigmatizing_labels.xlsx\n","'Copy of loneliness_social_isolation_lexicon_evaluation.csv'\n"," gold_standard_loneliness_lexicon_df.csv\n"," gold_standard_social_isolation_1000.csv\n"," loneliness_ehr_roberta.ipynb\n"," loneliness_gold_standard_expanded_lexicon_matches.xlsx\n"," loneliness_lexicon_dev.ipynb\n"," loneliness_lexicon.Rmd\n"," loneliness_lexicon_stem_and_similar_round1.csv\n"," loneliness_lexicon_stem_and_similar_round2.csv\n"," loneliness_matches_expanded.xlsx\n"," loneliness_matches.xlsx\n"," loneliness_regex_matching_and_sample.ipynb\n"," loneliness_roberta_ehr_performance.gsheet\n"," loneliness_social_isolation_lexicon_evaluation.csv\n","'loneliness_social_isolation_lexicon_evaluation KL.csv'\n","'Matched Terms from Social Disconnection Lexicon.png'\n"," new_loneliness_phrases.csv\n"," predictions.csv\n"," reliability_sample_social_disconnection.xlsx\n"," reliability_sample_stigmatizing_labels.xlsx\n","'Top 20 Matched Terms from Expanded Loneliness Social Isolation Lexicon.png'\n","'Top 20 Matched Terms from Loneliness Social Isolation Lexicon.png'\n","'Top 20 Matched Terms from Social Disconnection Lexicon.png'\n","'Top 50 Matched Terms from Social Disconnection Lexicon.png'\n"]}],"source":["from google.colab import auth\n","auth.authenticate_user()\n","from google.colab import drive\n","drive.mount('/content/gdrive/')\n","\n","\n","%cd /content/gdrive/MyDrive/LonelinessR21\n","%ls"]},{"cell_type":"code","execution_count":null,"id":"9ce3248c-a66f-45ba-a649-d9b477bd7381","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":840,"status":"ok","timestamp":1728261685849,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"9ce3248c-a66f-45ba-a649-d9b477bd7381","outputId":"1a311fca-c235-4fec-aa62-96eec8886067"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 10 columns):\n"," #   Column                              Non-Null Count  Dtype  \n","---  ------                              --------------  -----  \n"," 0   Unnamed: 0                          1000 non-null   int64  \n"," 1   Sentence ID                         1000 non-null   int64  \n"," 2   TEXT                                1000 non-null   object \n"," 3   Sentence                            1000 non-null   object \n"," 4   matched_term                        1000 non-null   object \n"," 5   chronic_social_disconnection_label  1000 non-null   float64\n"," 6   lives_alone_label                   1000 non-null   float64\n"," 7   acute_social_disconnection_label    1000 non-null   float64\n"," 8   full_text                           1000 non-null   object \n"," 9   full_text_truncated                 1000 non-null   object \n","dtypes: float64(3), int64(2), object(5)\n","memory usage: 78.2+ KB\n"]}],"source":["df_concat_filtered  = pd.read_csv(\"gold_standard_social_isolation_1000.csv\")\n","df_concat_filtered.info()"]},{"cell_type":"code","execution_count":null,"id":"6de161ae-0296-4e45-8b35-b59cd1c3bdef","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"elapsed":177,"status":"ok","timestamp":1728261705112,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"6de161ae-0296-4e45-8b35-b59cd1c3bdef","outputId":"fbcf2204-72c1-40ae-f5c4-498268b93b55"},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 1000 entries, 0 to 999\n","Data columns (total 2 columns):\n"," #   Column  Non-Null Count  Dtype  \n","---  ------  --------------  -----  \n"," 0   label   1000 non-null   float64\n"," 1   text    1000 non-null   object \n","dtypes: float64(1), object(1)\n","memory usage: 15.8+ KB\n"]},{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"summary":"{\n  \"name\": \"unique_chronic_values\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7071067811865476,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.0,\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 441,\n        \"min\": 188,\n        \"max\": 812,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          188,\n          812\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"unique_chronic_values"},"text/html":["\n","  <div id=\"df-bba72020-407b-4e45-b156-590c84263d4f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>count</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.0</td>\n","      <td>812</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1.0</td>\n","      <td>188</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bba72020-407b-4e45-b156-590c84263d4f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bba72020-407b-4e45-b156-590c84263d4f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bba72020-407b-4e45-b156-590c84263d4f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7ecb9809-5b07-4950-9c77-f27cbc7becf0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7ecb9809-5b07-4950-9c77-f27cbc7becf0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7ecb9809-5b07-4950-9c77-f27cbc7becf0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","  <div id=\"id_5378c22f-bff1-48ec-b56e-720e1e46685b\">\n","    <style>\n","      .colab-df-generate {\n","        background-color: #E8F0FE;\n","        border: none;\n","        border-radius: 50%;\n","        cursor: pointer;\n","        display: none;\n","        fill: #1967D2;\n","        height: 32px;\n","        padding: 0 0 0 0;\n","        width: 32px;\n","      }\n","\n","      .colab-df-generate:hover {\n","        background-color: #E2EBFA;\n","        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","        fill: #174EA6;\n","      }\n","\n","      [theme=dark] .colab-df-generate {\n","        background-color: #3B4455;\n","        fill: #D2E3FC;\n","      }\n","\n","      [theme=dark] .colab-df-generate:hover {\n","        background-color: #434B5C;\n","        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","        fill: #FFFFFF;\n","      }\n","    </style>\n","    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('unique_chronic_values')\"\n","            title=\"Generate code using this dataframe.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n","  </svg>\n","    </button>\n","    <script>\n","      (() => {\n","      const buttonEl =\n","        document.querySelector('#id_5378c22f-bff1-48ec-b56e-720e1e46685b button.colab-df-generate');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      buttonEl.onclick = () => {\n","        google.colab.notebook.generateWithVariable('unique_chronic_values');\n","      }\n","      })();\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"],"text/plain":["   label  count\n","0    0.0    812\n","1    1.0    188"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\n","# Rename 'full_text_truncated' to 'text'\n","df_concat_filtered = df_concat_filtered.rename(columns={'full_text_truncated': 'text', 'lives_alone_label':'label'})\n","df_concat_filtered.reset_index(drop=True, inplace=True)\n","\n","# Create a new dataframe with the renamed 'text' column and 'chronic_social_disconnection_label'\n","chronic_df = df_concat_filtered[['label', 'text']]\n","\n","# Display the first few rows of chronic_df\n","chronic_df.info()\n","chronic_df.head()\n","chronic_df.reset_index(drop=True, inplace=True)\n","unique_chronic_values = chronic_df['label'].value_counts().reset_index()\n","\n","# Renaming columns for clarity\n","unique_chronic_values.columns = ['label', 'count']\n","unique_chronic_values\n","\n","\n"]},{"cell_type":"code","execution_count":null,"id":"921599ea-bf3f-4241-b4c5-b801245dba5b","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":343,"referenced_widgets":["1e91e72177c743bc85366f726efb46b8","2dbf83889fda472884e372c61fa14d52","e9d915f359cd4a1dabddcf6a3b7f4c3c","18c14b136a934f6bb581a67a1f75959f","bceb7ca7a9cb4bdc90a58c6ea7dcaa4f","8938202c940148e68c3216b88dd205bc","335bf09c26e54f0f85858476d391e671","b74e8477ce344aa683c3ca66e0f96892","95b015ad6a5346829587144f698f49d9","456f1d6a53de4c7da04dfa733d17e760","bf2ae2a315014da08fb235585a5941c5","7445655966f54f0c9dc817a9d7176920","0742e9a3b82b4b178f7ae31a650e7a3f","d2e917a03c4d4a40b4e40acad78499a5","210cfd549d3540cba3c59622a3b3a34d","e324230bb1f74d859760659e24ab51aa","e726209fb957474892fb1449f3bbaa79","0e69b41a7d1549ce83fd2e20b099c9c7","32a5c61cf4cc46b8843cad58a93103c4","986f5d37e3c94c3993b29bb05423fb5c","28e77c91e40049679d0b6218e8689958","d883293c7dea4b99867b8069ded6f29d","185fc044f7d24401826603fee46e626e","62f209fcafd14577b34b393455806909","cf2382dddd8d4f1f86bc9a64510d1a4b","2bcf02066c294ba2badab2ee60c965df","3e2e490f97274bd2bd3eea3fbb553e9d","2db228ce62a04b83882cda6b8d53c1ab","6ea6ea13006749a29c0198b2b466c66b","a7e383224d064b26be5ddcce796b59ac","6e40b64fe808422faf2bf6c463770980","d21823adc6194f3e9cf8a5ff991ae8c9","69dfd96e2a4241aea692ec2410397b6d","eab5498835c04ca5b26b5b428c57f8f2","fa9491bed6d44773b8b6b18231a66adf","c70001917c2042d88f8a0449b99ca00a","e80c023189ef48adb270d78a4aa85ab9","c1036d4817d54aae88261cc24dbdc38f","f99ec38dcb144da2966ce34048cce139","253716178122452baf5b2df2e924f66d","49cb67002f494deb925a5351464911d1","8c5dcf88bcfa4db9bfc269adfde84cd8","f65f4e5bc0834c02888c28fc39af3d18","2994575ce3074b21938f0c0af1d9ce8c","af59e45279da47eda5a5a14481229b7d","bb57a57feaf04f7dab0c5cbeb864e110","9882466f129647cca2efe092ee7f964e","f5d760a291ce4599bd25e61b5d7ce0dd","8061785d638441f0a7d2437f3860b5bc","b723d8db37224909b13393a6396ceb63","93e1c28095524c9d9e9f7281a2ff2059","658373519f654ba2b2d0b25abc1bf31e","c2257796d36e4353bb1c88fcdd22d1ee","e0d615aa26884f1198c1d5e04cb1b15a","6e840885a5f043528594efdc24b39f6c"]},"executionInfo":{"elapsed":1507,"status":"ok","timestamp":1728261724861,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"921599ea-bf3f-4241-b4c5-b801245dba5b","outputId":"0d7361c9-7c4b-46da-b907-e7c0f7c969af"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1e91e72177c743bc85366f726efb46b8","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7445655966f54f0c9dc817a9d7176920","version_major":2,"version_minor":0},"text/plain":["vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"185fc044f7d24401826603fee46e626e","version_major":2,"version_minor":0},"text/plain":["merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"eab5498835c04ca5b26b5b428c57f8f2","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"af59e45279da47eda5a5a14481229b7d","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]}],"source":["MAX_LEN = 512\n","TRAIN_BATCH_SIZE = 16\n","VALID_BATCH_SIZE = 16\n","EPOCHS = 10\n","LEARNING_RATE = 5e-06\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"]},{"cell_type":"code","execution_count":null,"id":"def3156d-02f7-4bee-8323-0eb67343b17c","metadata":{"id":"def3156d-02f7-4bee-8323-0eb67343b17c"},"outputs":[],"source":["class BiasData(Dataset):\n","    def __init__(self, dataframe, tokenizer, max_len):\n","        self.tokenizer = tokenizer\n","        self.data = dataframe\n","        self.text = dataframe.text\n","        self.targets = self.data.label\n","        self.max_len = max_len\n","\n","    def __len__(self):\n","        return len(self.text)\n","\n","    def __getitem__(self, index):\n","        if index >= len(self.text):\n","            raise IndexError(f\"Index {index} out of bounds for dataset of length {len(self.text)}\")\n","\n","        text = str(self.text[index])\n","        text = \" \".join(text.split())\n","\n","        inputs = self.tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=self.max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True,\n","            truncation=True\n","        )\n","        ids = inputs['input_ids']\n","        mask = inputs['attention_mask']\n","        token_type_ids = inputs[\"token_type_ids\"]\n","\n","        return {\n","            'ids': torch.tensor(ids, dtype=torch.long),\n","            'mask': torch.tensor(mask, dtype=torch.long),\n","            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n","            'targets': torch.tensor(self.targets[index], dtype=torch.float)\n","        }\n"]},{"cell_type":"code","execution_count":null,"id":"f4a7b645-1341-4d7c-a991-4281fda7350a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":189,"status":"ok","timestamp":1728261731557,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"f4a7b645-1341-4d7c-a991-4281fda7350a","outputId":"2a9c9d03-69f7-4816-dd99-ee8452f11c50"},"outputs":[{"name":"stdout","output_type":"stream","text":["FULL Dataset: (1000, 2)\n","TRAIN Dataset: (800, 2)\n","TEST Dataset: (200, 2)\n"]}],"source":["train_size = 0.8\n","train_data=chronic_df.sample(frac=train_size,random_state=0)\n","test_data=chronic_df.drop(train_data.index).reset_index(drop=True)\n","train_data = train_data.reset_index(drop=True)\n","\n","print(\"FULL Dataset: {}\".format(chronic_df.shape))\n","print(\"TRAIN Dataset: {}\".format(train_data.shape))\n","print(\"TEST Dataset: {}\".format(test_data.shape))\n","\n","training_set = BiasData(train_data, tokenizer, MAX_LEN)\n","testing_set = BiasData(test_data, tokenizer, MAX_LEN)"]},{"cell_type":"code","execution_count":null,"id":"98ae1748-139c-4255-bda0-81ea4184356f","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":162,"status":"ok","timestamp":1728261734851,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"98ae1748-139c-4255-bda0-81ea4184356f","outputId":"8d08a721-ce8b-4966-d27f-69569acab89b"},"outputs":[{"data":{"text/plain":["array([0., 1.])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["train_data['label'].unique()"]},{"cell_type":"code","execution_count":null,"id":"45faafa9-d322-401d-aa69-aa491a38777f","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":241},"executionInfo":{"elapsed":305,"status":"ok","timestamp":1728261741481,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"45faafa9-d322-401d-aa69-aa491a38777f","outputId":"15bc12d1-e692-489b-907d-2b035e5312a5"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Ischemic disease was excluded (no EKG changes,...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>As other etiologies for bladder wall thickenin...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>MAE, patient is cooparative with but seems to ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Social: Found down in apartment alone.&lt;/s&gt;T/SI...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>It may represent extension / recurrence of a t...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> object</label>"],"text/plain":["0    Ischemic disease was excluded (no EKG changes,...\n","1    As other etiologies for bladder wall thickenin...\n","2    MAE, patient is cooparative with but seems to ...\n","3    Social: Found down in apartment alone.</s>T/SI...\n","4    It may represent extension / recurrence of a t...\n","Name: text, dtype: object"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["test_data['label'].unique()\n","test_data['text'].head()"]},{"cell_type":"code","execution_count":null,"id":"5024e414-4a6e-4070-a56a-7a4465484709","metadata":{"id":"5024e414-4a6e-4070-a56a-7a4465484709"},"outputs":[],"source":["train_params = {'batch_size': TRAIN_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","test_params = {'batch_size': VALID_BATCH_SIZE,\n","                'shuffle': True,\n","                'num_workers': 0\n","                }\n","\n","training_loader = DataLoader(training_set, **train_params)\n","testing_loader = DataLoader(testing_set, **test_params)"]},{"cell_type":"code","execution_count":null,"id":"d4a48b5f-37af-4aa5-b168-739c6b756999","metadata":{"id":"d4a48b5f-37af-4aa5-b168-739c6b756999"},"outputs":[],"source":["from transformers import RobertaConfig\n","\n","config = RobertaConfig.from_pretrained(\"roberta-base\")\n","config.output_attentions = True\n","\n","class RobertaClass(torch.nn.Module):\n","    def __init__(self):\n","        super(RobertaClass, self).__init__()\n","        self.l1 = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n","        self.pre_classifier = torch.nn.Linear(768, 768)\n","        self.dropout = torch.nn.Dropout(0.0)\n","        self.classifier = torch.nn.Linear(768, 2)\n","\n","    def forward(self, input_ids, attention_mask):\n","        # Get the hidden states, pooler output, and attention weights\n","        last_hidden_state, pooler_output, all_attentions = self.l1(input_ids=input_ids, attention_mask=attention_mask, return_dict=False)\n","        pooler = last_hidden_state[:, 0]\n","        pooler = self.pre_classifier(pooler)\n","        pooler = torch.nn.ReLU()(pooler)\n","        pooler = self.dropout(pooler)\n","        output = self.classifier(pooler)\n","        return output, all_attentions\n","\n"]},{"cell_type":"code","execution_count":null,"id":"d4d453a9-7873-42eb-98f5-40a8bc6a48bc","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":924,"referenced_widgets":["ebb167e0250a4228b61940c1c9aaa78a","5a0855e82ade4c59bdb558a537a13c50","170b07d6b017429ca29447a77536b99f","f23d8c7e18f04d228b8428307af1c35f","bd66c1627fdd4777b39dcfe09481476a","a9ff3febb4b54cd4be47e49f9bfc7d0d","88e6c54498de473c9670af6307eca3ec","a98d428762d641049c5bb635fa967ba3","b833ce35cf64413bbbf4d502054e6041","10d8af2471e24295b4b47485c1fe100f","c04a275d19224fb5865faef75053466b"]},"executionInfo":{"elapsed":2587,"status":"ok","timestamp":1728261751889,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"d4d453a9-7873-42eb-98f5-40a8bc6a48bc","outputId":"91413976-241c-4924-cdd7-a03b5aab1af7"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ebb167e0250a4228b61940c1c9aaa78a","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"data":{"text/plain":["RobertaClass(\n","  (l1): RobertaModel(\n","    (embeddings): RobertaEmbeddings(\n","      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n","      (position_embeddings): Embedding(514, 768, padding_idx=1)\n","      (token_type_embeddings): Embedding(1, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): RobertaEncoder(\n","      (layer): ModuleList(\n","        (0-11): 12 x RobertaLayer(\n","          (attention): RobertaAttention(\n","            (self): RobertaSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): RobertaSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): RobertaIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): RobertaOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): RobertaPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n","  (dropout): Dropout(p=0.0, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = RobertaClass()\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"id":"4f1b0538-b63b-44dd-991f-eafb99b4f8eb","metadata":{"id":"4f1b0538-b63b-44dd-991f-eafb99b4f8eb"},"outputs":[],"source":["# Creating the loss function and optimizer\n","loss_function = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"id":"561a0c8c-f039-4314-9661-ee6e23f575f2","metadata":{"id":"561a0c8c-f039-4314-9661-ee6e23f575f2"},"outputs":[],"source":["def calcuate_accuracy(preds, targets):\n","    n_correct = (preds==targets).sum().item()\n","    return n_correct"]},{"cell_type":"code","execution_count":null,"id":"d1dd7588-6fb4-456b-bde3-4ab16945334e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":219,"status":"ok","timestamp":1728261756602,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"},"user_tz":240},"id":"d1dd7588-6fb4-456b-bde3-4ab16945334e","outputId":"5b216f06-d13e-48af-d399-b289ca8793c1"},"outputs":[{"name":"stdout","output_type":"stream","text":["800\n"]}],"source":["def train(epoch):\n","    tr_loss = 0\n","    n_correct = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","    model.train()\n","    for _,data in tqdm(enumerate(training_loader, 0)):\n","        ids = data['ids'].to(device, dtype = torch.long)\n","        mask = data['mask'].to(device, dtype = torch.long)\n","        targets = data['targets'].to(device, dtype = torch.long)\n","\n","        # Extract the logits (output) from the returned tuple\n","        logits, attention_weights = model(ids, mask)\n","\n","        # Use the logits when computing the loss\n","        loss = loss_function(logits, targets)\n","        tr_loss += loss.item()\n","        big_val, big_idx = torch.max(logits.data, dim=1)\n","        n_correct += calcuate_accuracy(big_idx, targets)\n","\n","        nb_tr_steps += 1\n","        nb_tr_examples += targets.size(0)\n","\n","        if _ % 5000 == 0:\n","            loss_step = tr_loss / nb_tr_steps\n","            accu_step = (n_correct * 100) / nb_tr_examples\n","            print(f\"Training Loss: {loss_step}\")\n","            print(f\"Training Accuracy: {accu_step}\")\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n","    epoch_loss = tr_loss / nb_tr_steps\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","    print(f\"Training Loss Epoch: {epoch_loss}\")\n","    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n","\n","    return\n","\n","\n","print(len(training_loader.dataset))\n","\n"]},{"cell_type":"code","execution_count":null,"id":"161f74a5-1610-4884-9fad-b103781a9a1a","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"161f74a5-1610-4884-9fad-b103781a9a1a","outputId":"44f32f29-576f-48f9-8113-45d34b6adafd"},"outputs":[{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.7009543776512146\n","Training Accuracy: 31.25\n"]},{"name":"stderr","output_type":"stream","text":["50it [23:34, 28.29s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 0: 79.5\n","Training Loss Epoch: 0.5468260771036149\n","Training Accuracy Epoch: 79.5\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.5440639853477478\n","Training Accuracy: 75.0\n"]},{"name":"stderr","output_type":"stream","text":["50it [22:59, 27.58s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 1: 81.0\n","Training Loss Epoch: 0.4310170644521713\n","Training Accuracy Epoch: 81.0\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.2736508548259735\n","Training Accuracy: 87.5\n"]},{"name":"stderr","output_type":"stream","text":["50it [23:00, 27.62s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 2: 83.125\n","Training Loss Epoch: 0.3083496432006359\n","Training Accuracy Epoch: 83.125\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.2689298391342163\n","Training Accuracy: 100.0\n"]},{"name":"stderr","output_type":"stream","text":["50it [22:58, 27.56s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 3: 92.875\n","Training Loss Epoch: 0.217487154006958\n","Training Accuracy Epoch: 92.875\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.28661519289016724\n","Training Accuracy: 87.5\n"]},{"name":"stderr","output_type":"stream","text":["50it [22:53, 27.48s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 4: 94.5\n","Training Loss Epoch: 0.15603340234607457\n","Training Accuracy Epoch: 94.5\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.03223927691578865\n","Training Accuracy: 100.0\n"]},{"name":"stderr","output_type":"stream","text":["50it [23:14, 27.89s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 5: 95.625\n","Training Loss Epoch: 0.13180535476654767\n","Training Accuracy Epoch: 95.625\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.048806946724653244\n","Training Accuracy: 100.0\n"]},{"name":"stderr","output_type":"stream","text":["50it [22:53, 27.47s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 6: 97.125\n","Training Loss Epoch: 0.09560710441321135\n","Training Accuracy Epoch: 97.125\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.18682622909545898\n","Training Accuracy: 93.75\n"]},{"name":"stderr","output_type":"stream","text":["50it [23:01, 27.63s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 7: 97.75\n","Training Loss Epoch: 0.07867609402164817\n","Training Accuracy Epoch: 97.75\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.02907380275428295\n","Training Accuracy: 100.0\n"]},{"name":"stderr","output_type":"stream","text":["50it [23:35, 28.31s/it]\n"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 8: 98.375\n","Training Loss Epoch: 0.0656135606765747\n","Training Accuracy Epoch: 98.375\n"]},{"name":"stderr","output_type":"stream","text":["\r0it [00:00, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["Training Loss: 0.10602328181266785\n","Training Accuracy: 93.75\n"]},{"name":"stderr","output_type":"stream","text":["50it [22:59, 27.58s/it]"]},{"name":"stdout","output_type":"stream","text":["The Total Accuracy for Epoch 9: 98.0\n","Training Loss Epoch: 0.07357963291928173\n","Training Accuracy Epoch: 98.0\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["for epoch in range(EPOCHS):\n","    train(epoch)"]},{"cell_type":"code","execution_count":null,"id":"8be77efb-a5c0-432d-ade0-c3afa5d754ed","metadata":{"colab":{"background_save":true},"id":"8be77efb-a5c0-432d-ade0-c3afa5d754ed"},"outputs":[],"source":["def valid(model, testing_loader):\n","    model.eval()\n","    n_correct = 0\n","    tr_loss = 0\n","    nb_tr_steps = 0\n","    nb_tr_examples = 0\n","\n","    all_preds = []  # list to store predictions\n","    all_targets = []  # list to store original targets\n","    all_texts = []  # list to store original input texts\n","\n","    with torch.no_grad():\n","        for _, data in tqdm(enumerate(testing_loader, 0)):\n","            ids = data['ids'].to(device, dtype=torch.long)\n","            mask = data['mask'].to(device, dtype=torch.long)\n","            targets = data['targets'].to(device, dtype=torch.long)\n","\n","            # Extract the logits (output) from the returned tuple\n","            logits, attention_weights = model(ids, mask)\n","            logits = logits.squeeze()\n","\n","            # Use the logits when computing the loss and other operations\n","            loss = loss_function(logits, targets)\n","            tr_loss += loss.item()\n","            big_val, big_idx = torch.max(logits.data, dim=1)\n","\n","            all_preds.extend(big_idx.cpu().numpy())  # store predictions\n","            all_targets.extend(targets.cpu().numpy())  # store targets\n","\n","            all_texts.extend(data['ids'])  # store original input texts\n","\n","            n_correct += calcuate_accuracy(big_idx, targets)\n","\n","            nb_tr_steps += 1\n","            nb_tr_examples += targets.size(0)\n","\n","            if _ % 5000 == 0:\n","                loss_step = tr_loss / nb_tr_steps\n","                accu_step = (n_correct * 100) / nb_tr_examples\n","                print(f\"Validation Loss: {loss_step}\")\n","                print(f\"Validation Accuracy: {accu_step}\")\n","\n","    epoch_loss = tr_loss / nb_tr_steps\n","    epoch_accu = (n_correct * 100) / nb_tr_examples\n","\n","    print(f\"Validation Loss Epoch: {epoch_loss}\")\n","    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n","\n","    # Print classification report\n","    report = classification_report(all_targets, all_preds)\n","    print(report)\n","\n","    # Confusion matrix\n","    cm = confusion_matrix(all_targets, all_preds)\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","\n","    # Create a DataFrame and save it\n","    df_predictions = pd.DataFrame({\n","        'Text': all_texts,\n","        'Original': all_targets,\n","        'Predicted': all_preds\n","    })\n","    df_predictions.to_csv('predictions.csv', index=False)\n","    print(df_predictions.head())\n","\n","    return epoch_accu\n","\n"]},{"cell_type":"code","execution_count":null,"id":"179e481d-9ac7-4d3e-9fa0-9a587a1de656","metadata":{"id":"179e481d-9ac7-4d3e-9fa0-9a587a1de656"},"outputs":[],"source":["## VALIDATION"]},{"cell_type":"code","execution_count":null,"id":"f8414380-f954-400e-8337-c732a1087e1b","metadata":{"colab":{"background_save":true},"id":"f8414380-f954-400e-8337-c732a1087e1b","outputId":"85dcfb53-0073-45fe-d8e8-4288bd23d995"},"outputs":[{"name":"stderr","output_type":"stream","text":["1it [00:08,  8.06s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.015424137935042381\n","Validation Accuracy: 100.0\n"]},{"name":"stderr","output_type":"stream","text":["13it [01:40,  7.75s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss Epoch: 0.07134791528089689\n","Validation Accuracy Epoch: 97.5\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98       164\n","           1       0.88      1.00      0.94        36\n","\n","    accuracy                           0.97       200\n","   macro avg       0.94      0.98      0.96       200\n","weighted avg       0.98      0.97      0.98       200\n","\n","Confusion Matrix:\n","[[159   5]\n"," [  0  36]]\n","                                                Text  Original  Predicted\n","0  [tensor(0), tensor(1620), tensor(97), tensor(4...         0          0\n","1  [tensor(0), tensor(47874), tensor(35), tensor(...         0          0\n","2  [tensor(0), tensor(26369), tensor(3935), tenso...         0          0\n","3  [tensor(0), tensor(4688), tensor(6256), tensor...         0          0\n","4  [tensor(0), tensor(34440), tensor(31995), tens...         0          0\n"]},{"name":"stderr","output_type":"stream","text":["0it [00:00, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n","1it [00:07,  7.48s/it]"]},{"name":"stdout","output_type":"stream","text":["Validation Loss: 0.04283013567328453\n","Validation Accuracy: 100.0\n"]},{"name":"stderr","output_type":"stream","text":["13it [01:40,  7.76s/it]\n"]},{"name":"stdout","output_type":"stream","text":["Validation Loss Epoch: 0.07175443615191258\n","Validation Accuracy Epoch: 97.5\n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98       164\n","           1       0.88      1.00      0.94        36\n","\n","    accuracy                           0.97       200\n","   macro avg       0.94      0.98      0.96       200\n","weighted avg       0.98      0.97      0.98       200\n","\n","Confusion Matrix:\n","[[159   5]\n"," [  0  36]]\n","                                                Text  Original  Predicted\n","0  [tensor(0), tensor(5632), tensor(31798), tenso...         0          0\n","1  [tensor(0), tensor(574), tensor(3699), tensor(...         1          1\n","2  [tensor(0), tensor(713), tensor(16), tensor(14...         0          0\n","3  [tensor(0), tensor(18547), tensor(139), tensor...         0          0\n","4  [tensor(0), tensor(387), tensor(16908), tensor...         0          0\n","test accuracy = 97.50%\n","Elapsed Time: 14233.38 seconds\n"]}],"source":["valid(model, testing_loader)\n","\n","acc = valid(model,testing_loader)\n","print(\"test accuracy = %0.2f%%\" % acc)\n","\n","end_time = time.time()\n","\n","elapsed_time = end_time - start_time\n","print(f\"Elapsed Time: {elapsed_time:.2f} seconds\")\n","\n"]},{"cell_type":"code","execution_count":null,"id":"8ac0ac19-c4a8-41f6-95ab-bda445348f93","metadata":{"id":"8ac0ac19-c4a8-41f6-95ab-bda445348f93"},"outputs":[],"source":["## PREDICTIONS"]},{"cell_type":"code","execution_count":null,"id":"5e6b266f-8ac2-4e0c-85dc-ef60b5f0a0e6","metadata":{"colab":{"background_save":true},"id":"5e6b266f-8ac2-4e0c-85dc-ef60b5f0a0e6"},"outputs":[],"source":["def predict_on_dataframe(df, model, tokenizer, max_len):\n","    model.eval()\n","    predictions = []\n","\n","    for index, row in df.iterrows():\n","        text = row['text']\n","        inputs = tokenizer.encode_plus(\n","            text,\n","            None,\n","            add_special_tokens=True,\n","            max_length=max_len,\n","            pad_to_max_length=True,\n","            return_token_type_ids=True\n","        )\n","        ids = torch.tensor([inputs['input_ids']], dtype=torch.long).to(device)\n","        mask = torch.tensor([inputs['attention_mask']], dtype=torch.long).to(device)\n","\n","        with torch.no_grad():\n","            logits, _ = model(ids, mask)  # Here we unpack the tuple\n","\n","        big_val, big_idx = torch.max(logits.data, dim=1)  # Use logits instead of outputs\n","        predictions.append(big_idx[0].item())\n","\n","    df['predictions'] = predictions\n","    return pd.DataFrame(df)\n","\n"]},{"cell_type":"code","execution_count":null,"id":"ecf44c78-8693-46f6-82ad-0760b279fceb","metadata":{"colab":{"background_save":true},"id":"ecf44c78-8693-46f6-82ad-0760b279fceb","outputId":"4456f051-9fd0-45e1-d2cb-fe9571fe89d6"},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2870: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["     label                                               text  predictions\n","0      0.0  The electronic pacer device overlying the left...            0\n","1      0.0  No attempts to get OOB alone.</s>87 year old f...            0\n","2      0.0  Neuro: Pt remains withdrawn, opens eyes sponta...            0\n","3      1.0  FWB'ing B LE Social / Occupational History: Pt...            1\n","4      0.0  Response: Plan: .H/O anxiety Assessment: Letha...            0\n","..     ...                                                ...          ...\n","995    1.0  Lives at home alone, has home aide come in eve...            1\n","996    0.0  POST EXTUBATION PT CALM AND WITHDRAWN.</s>MICU...            0\n","997    0.0  I spoke with [**First Name8 (NamePattern2) 862...            0\n","998    0.0  #5: Mom in for few mins this am alone.</s>NPN ...            0\n","999    0.0  When family here they think she is [** 467**] ...            0\n","\n","[1000 rows x 3 columns]\n"]},{"name":"stderr","output_type":"stream","text":["<ipython-input-19-f46c646d3b1d>:24: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  df['predictions'] = predictions\n"]}],"source":["predicted_classes = predict_on_dataframe(chronic_df, model, tokenizer, max_len=512)\n","print(predicted_classes)\n"]},{"cell_type":"code","execution_count":null,"id":"4441fe5a-eb4a-4fa3-a8c1-5c6f48bab8be","metadata":{"id":"4441fe5a-eb4a-4fa3-a8c1-5c6f48bab8be","executionInfo":{"status":"ok","timestamp":1728277127992,"user_tz":240,"elapsed":9064,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"39c3d63d-d3b8-40e3-9139-d2f6f50b7577","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["F1 Score: Mean=0.942, 95% CI=(0.918, 0.963)\n","Precision: Mean=0.894, 95% CI=(0.850, 0.934)\n","Recall: Mean=0.994, 95% CI=(0.981, 1.000)\n","Accuracy: Mean=0.977, 95% CI=(0.967, 0.985)\n"]}],"source":["from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n","import numpy as np\n","\n","# Assuming predicted_classes is a DataFrame with 'label' and 'predictions' columns\n","true_labels = predicted_classes['label'].tolist()  # Extract 'label' column as list\n","predicted_labels = predicted_classes['predictions'].tolist()  # Extract 'predictions' column as list\n","\n","# Function for bootstrapping a metric\n","def bootstrap_metric(y_true, y_pred, metric_func, n_iterations=1000):\n","    bootstrap_values = []\n","    n_samples = len(y_true)\n","    for _ in range(n_iterations):\n","        indices = np.random.choice(np.arange(n_samples), size=n_samples, replace=True)\n","        bootstrap_true = np.array(y_true)[indices]\n","        bootstrap_pred = np.array(y_pred)[indices]\n","        value = metric_func(bootstrap_true, bootstrap_pred)\n","        bootstrap_values.append(value)\n","    return bootstrap_values\n","\n","# Bootstrapping each metric for the positive class (label = 1)\n","bootstrap_f1_pos = bootstrap_metric(true_labels, predicted_labels, lambda y_true, y_pred: f1_score(y_true, y_pred, pos_label=1))\n","bootstrap_precision_pos = bootstrap_metric(true_labels, predicted_labels, lambda y_true, y_pred: precision_score(y_true, y_pred, pos_label=1))\n","bootstrap_recall_pos = bootstrap_metric(true_labels, predicted_labels, lambda y_true, y_pred: recall_score(y_true, y_pred, pos_label=1))\n","bootstrap_accuracy = bootstrap_metric(true_labels, predicted_labels, accuracy_score)\n","\n","# Function to compute mean and confidence intervals\n","def mean_and_confidence_interval(data, alpha=0.05):\n","    mean_value = np.mean(data)\n","    lower_percentile = 100 * alpha / 2.\n","    upper_percentile = 100 * (1 - alpha / 2.)\n","    lower = np.percentile(data, lower_percentile)\n","    upper = np.percentile(data, upper_percentile)\n","    return mean_value, lower, upper\n","\n","# Compute mean and confidence intervals for each metric\n","f1_mean, f1_lower, f1_upper = mean_and_confidence_interval(bootstrap_f1_pos)\n","precision_mean, precision_lower, precision_upper = mean_and_confidence_interval(bootstrap_precision_pos)\n","recall_mean, recall_lower, recall_upper = mean_and_confidence_interval(bootstrap_recall_pos)\n","accuracy_mean, accuracy_lower, accuracy_upper = mean_and_confidence_interval(bootstrap_accuracy)\n","\n","# Print results\n","print(f\"F1 Score: Mean={f1_mean:.3f}, 95% CI=({f1_lower:.3f}, {f1_upper:.3f})\")\n","print(f\"Precision: Mean={precision_mean:.3f}, 95% CI=({precision_lower:.3f}, {precision_upper:.3f})\")\n","print(f\"Recall: Mean={recall_mean:.3f}, 95% CI=({recall_lower:.3f}, {recall_upper:.3f})\")\n","print(f\"Accuracy: Mean={accuracy_mean:.3f}, 95% CI=({accuracy_lower:.3f}, {accuracy_upper:.3f})\")\n","\n","\n"]},{"cell_type":"code","source":["!pip install shap\n","#visualization shapley"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YmpOF2KFYgyu","executionInfo":{"status":"ok","timestamp":1728277811920,"user_tz":240,"elapsed":3845,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"978528ec-2157-4d4e-9102-f8e516ef8155"},"id":"YmpOF2KFYgyu","execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting shap\n","  Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (24 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.26.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.13.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.2)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.5)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (24.1)\n","Collecting slicer==0.0.8 (from shap)\n","  Downloading slicer-0.0.8-py3-none-any.whl.metadata (4.0 kB)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2024.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.5.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n","Downloading shap-0.46.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (540 kB)\n","\u001b[2K   \u001b[90m\u001b[0m \u001b[32m540.1/540.1 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading slicer-0.0.8-py3-none-any.whl (15 kB)\n","Installing collected packages: slicer, shap\n","Successfully installed shap-0.46.0 slicer-0.0.8\n"]}]},{"cell_type":"code","source":["import shap\n","import torch\n","from transformers import RobertaTokenizer\n","import numpy as np\n","\n","# Load the tokenizer and the pre-trained RoBERTa model (assumed already trained on your task)\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","# Example sentences you want to explain\n","sentences = [\n","    \"Past Medical History: DMII with retinopathy fatty liver obesity constipation COPD HL DJD atypical chest pain schizoaffective disorder substance abuse Social History: Lives alone in [Location Name].\",\n","    \"Pt was living at home alone prior to hospitalization.\"\n","]\n","\n","# Tokenize the sentences\n","tokenized_inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n","\n","# Extract input_ids and attention_mask for SHAP\n","input_ids = tokenized_inputs['input_ids']\n","attention_mask = tokenized_inputs['attention_mask']\n","\n","# Move input tensors to the correct device (GPU if available)\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","input_ids = input_ids.to(device)\n","attention_mask = attention_mask.to(device)\n","model = model.to(device)  # Ensure the model is on the same device\n","\n","# Create SHAP explainer with DeepExplainer for transformers\n","explainer = shap.DeepExplainer(model, input_ids)\n","\n","# Explain the model's predictions\n","shap_values = explainer.shap_values(input_ids)\n","\n","# Convert input IDs to tokens for visualization\n","feature_names = tokenizer.convert_ids_to_tokens(input_ids[0].tolist())\n","\n","# Visualize the SHAP values for the first sentence\n","shap.summary_plot(shap_values[0], feature_names=feature_names)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":356},"id":"315mFp_dYkSx","executionInfo":{"status":"error","timestamp":1728278405792,"user_tz":240,"elapsed":308,"user":{"displayName":"Drew Walker","userId":"14045603896542101477"}},"outputId":"1a8f5a83-572d-4c05-b3d5-84e9fc705727"},"id":"315mFp_dYkSx","execution_count":34,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"RobertaClass.forward() missing 1 required positional argument: 'attention_mask'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-34-dc323211beb6>\u001b[0m in \u001b[0;36m<cell line: 29>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Create SHAP explainer with DeepExplainer for transformers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Explain the model's predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data, session, learning_phase_flags)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTFDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_phase_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mframework\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pytorch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPyTorchDeep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/shap/explainers/_deep/deep_pytorch.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# also get the device everything is running on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: RobertaClass.forward() missing 1 required positional argument: 'attention_mask'"]}]},{"cell_type":"code","execution_count":null,"id":"VQSXhqXk3CQq","metadata":{"id":"VQSXhqXk3CQq"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import torch\n","from sklearn.model_selection import StratifiedKFold\n","from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n","from sklearn.metrics import f1_score\n","from torch.utils.data import Dataset, DataLoader\n","\n","# Load the tokenizer\n","tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","\n","# Define a custom Dataset class\n","class CustomTextDataset(Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[idx])\n","        return item\n","\n","# Tokenize the text data\n","def tokenize_function(texts):\n","    return tokenizer(texts, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n","\n","# Placeholder for chronic_df (ensure it's a pandas DataFrame)\n","X = chronic_df['text'].values\n","y = chronic_df['label'].values\n","\n","skf = StratifiedKFold(n_splits=5)\n","\n","# Empty lists to store sample sizes and F1 scores\n","sample_sizes = []\n","f1_scores = []\n","\n","# Main training loop (fixed to handle class indices correctly)\n","for sample_size in range(100, 1001, 100):\n","    f1_scores_sample = []\n","\n","    for train_index, test_index in skf.split(X, y):\n","        # Select training and test data and ensure labels are integers\n","        train_texts = X[train_index[:sample_size]].tolist()\n","        test_texts = X[test_index].tolist()\n","        train_labels = y[train_index[:sample_size]].astype(int)  # Ensure labels are integers\n","        test_labels = y[test_index].astype(int)  # Ensure labels are integers\n","\n","        # Tokenize the datasets\n","        train_encodings = tokenize_function(train_texts)\n","        test_encodings = tokenize_function(test_texts)\n","\n","        # Create custom PyTorch datasets\n","        train_dataset = CustomTextDataset(train_encodings, train_labels)\n","        test_dataset = CustomTextDataset(test_encodings, test_labels)\n","\n","        # Load the RoBERTa model for classification (2 classes)\n","        model = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=2)\n","\n","        # Set up training arguments\n","        training_args = TrainingArguments(\n","            output_dir='./results',\n","            num_train_epochs=3,\n","            per_device_train_batch_size=8,\n","            per_device_eval_batch_size=8,\n","            warmup_steps=500,\n","            weight_decay=0.01,\n","            logging_dir='./logs',\n","            logging_steps=10,\n","        )\n","\n","        # Define Trainer\n","        trainer = Trainer(\n","            model=model,\n","            args=training_args,\n","            train_dataset=train_dataset,\n","            eval_dataset=test_dataset\n","        )\n","\n","        # Train the model\n","        trainer.train()\n","\n","        # Get predictions\n","        predictions = trainer.predict(test_dataset).predictions.argmax(-1)  # Use argmax to get class predictions\n","\n","        # Calculate F1 score\n","        f1 = f1_score(test_labels, predictions, average='binary')\n","        f1_scores_sample.append(f1)\n","\n","    # Store the mean F1 score for this sample size\n","    sample_sizes.append(sample_size)\n","    f1_scores.append(np.mean(f1_scores_sample))\n","\n","# Create a DataFrame for the results\n","results_df = pd.DataFrame({'Sample Size': sample_sizes, 'F1 Score': f1_scores})\n","\n","# Plot the results (as before)\n","import matplotlib.pyplot as plt\n","plt.figure(figsize=(10, 6))\n","plt.plot(results_df['Sample Size'], results_df['F1 Score'], marker='o', linestyle='-', color='b')\n","plt.title('Live Alone Sample Size vs F1 Score for RoBERTa Model')\n","plt.xlabel('Sample Size')\n","plt.ylabel('F1 Score')\n","plt.grid(True)\n","plt.savefig(\"live_alone_loneliness_sample_size_f1_roberta.png\")\n","\n","# Save results to CSV\n","results_df.to_csv(\"live_alone_loneliness_sample_size_vs_f1_score_roberta.csv\", index=False)\n","\n"]}],"metadata":{"colab":{"machine_shape":"hm","provenance":[{"file_id":"1PUML9mCTQdSBLypnh7TP24G1yyzNUGPg","timestamp":1728261553928},{"file_id":"1j3qVzXi3XdW-n5vJoT2_ckZxZprjig0D","timestamp":1728261283011}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0742e9a3b82b4b178f7ae31a650e7a3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e726209fb957474892fb1449f3bbaa79","placeholder":"","style":"IPY_MODEL_0e69b41a7d1549ce83fd2e20b099c9c7","value":"vocab.json:100%"}},"0e69b41a7d1549ce83fd2e20b099c9c7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"10d8af2471e24295b4b47485c1fe100f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"170b07d6b017429ca29447a77536b99f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a98d428762d641049c5bb635fa967ba3","max":498818054,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b833ce35cf64413bbbf4d502054e6041","value":498818054}},"185fc044f7d24401826603fee46e626e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_62f209fcafd14577b34b393455806909","IPY_MODEL_cf2382dddd8d4f1f86bc9a64510d1a4b","IPY_MODEL_2bcf02066c294ba2badab2ee60c965df"],"layout":"IPY_MODEL_3e2e490f97274bd2bd3eea3fbb553e9d"}},"18c14b136a934f6bb581a67a1f75959f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_456f1d6a53de4c7da04dfa733d17e760","placeholder":"","style":"IPY_MODEL_bf2ae2a315014da08fb235585a5941c5","value":"25.0/25.0[00:00&lt;00:00,1.34kB/s]"}},"1e91e72177c743bc85366f726efb46b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2dbf83889fda472884e372c61fa14d52","IPY_MODEL_e9d915f359cd4a1dabddcf6a3b7f4c3c","IPY_MODEL_18c14b136a934f6bb581a67a1f75959f"],"layout":"IPY_MODEL_bceb7ca7a9cb4bdc90a58c6ea7dcaa4f"}},"210cfd549d3540cba3c59622a3b3a34d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_28e77c91e40049679d0b6218e8689958","placeholder":"","style":"IPY_MODEL_d883293c7dea4b99867b8069ded6f29d","value":"899k/899k[00:00&lt;00:00,9.69MB/s]"}},"253716178122452baf5b2df2e924f66d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28e77c91e40049679d0b6218e8689958":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2994575ce3074b21938f0c0af1d9ce8c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bcf02066c294ba2badab2ee60c965df":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d21823adc6194f3e9cf8a5ff991ae8c9","placeholder":"","style":"IPY_MODEL_69dfd96e2a4241aea692ec2410397b6d","value":"456k/456k[00:00&lt;00:00,18.2MB/s]"}},"2db228ce62a04b83882cda6b8d53c1ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2dbf83889fda472884e372c61fa14d52":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8938202c940148e68c3216b88dd205bc","placeholder":"","style":"IPY_MODEL_335bf09c26e54f0f85858476d391e671","value":"tokenizer_config.json:100%"}},"32a5c61cf4cc46b8843cad58a93103c4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"335bf09c26e54f0f85858476d391e671":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e2e490f97274bd2bd3eea3fbb553e9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"456f1d6a53de4c7da04dfa733d17e760":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"49cb67002f494deb925a5351464911d1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a0855e82ade4c59bdb558a537a13c50":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9ff3febb4b54cd4be47e49f9bfc7d0d","placeholder":"","style":"IPY_MODEL_88e6c54498de473c9670af6307eca3ec","value":"model.safetensors:100%"}},"62f209fcafd14577b34b393455806909":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2db228ce62a04b83882cda6b8d53c1ab","placeholder":"","style":"IPY_MODEL_6ea6ea13006749a29c0198b2b466c66b","value":"merges.txt:100%"}},"658373519f654ba2b2d0b25abc1bf31e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69dfd96e2a4241aea692ec2410397b6d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e40b64fe808422faf2bf6c463770980":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6e840885a5f043528594efdc24b39f6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ea6ea13006749a29c0198b2b466c66b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7445655966f54f0c9dc817a9d7176920":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0742e9a3b82b4b178f7ae31a650e7a3f","IPY_MODEL_d2e917a03c4d4a40b4e40acad78499a5","IPY_MODEL_210cfd549d3540cba3c59622a3b3a34d"],"layout":"IPY_MODEL_e324230bb1f74d859760659e24ab51aa"}},"8061785d638441f0a7d2437f3860b5bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e6c54498de473c9670af6307eca3ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8938202c940148e68c3216b88dd205bc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c5dcf88bcfa4db9bfc269adfde84cd8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"93e1c28095524c9d9e9f7281a2ff2059":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95b015ad6a5346829587144f698f49d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"986f5d37e3c94c3993b29bb05423fb5c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9882466f129647cca2efe092ee7f964e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_658373519f654ba2b2d0b25abc1bf31e","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c2257796d36e4353bb1c88fcdd22d1ee","value":481}},"a7e383224d064b26be5ddcce796b59ac":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a98d428762d641049c5bb635fa967ba3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9ff3febb4b54cd4be47e49f9bfc7d0d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af59e45279da47eda5a5a14481229b7d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bb57a57feaf04f7dab0c5cbeb864e110","IPY_MODEL_9882466f129647cca2efe092ee7f964e","IPY_MODEL_f5d760a291ce4599bd25e61b5d7ce0dd"],"layout":"IPY_MODEL_8061785d638441f0a7d2437f3860b5bc"}},"b723d8db37224909b13393a6396ceb63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b74e8477ce344aa683c3ca66e0f96892":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b833ce35cf64413bbbf4d502054e6041":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"bb57a57feaf04f7dab0c5cbeb864e110":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b723d8db37224909b13393a6396ceb63","placeholder":"","style":"IPY_MODEL_93e1c28095524c9d9e9f7281a2ff2059","value":"config.json:100%"}},"bceb7ca7a9cb4bdc90a58c6ea7dcaa4f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd66c1627fdd4777b39dcfe09481476a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf2ae2a315014da08fb235585a5941c5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c04a275d19224fb5865faef75053466b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c1036d4817d54aae88261cc24dbdc38f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2257796d36e4353bb1c88fcdd22d1ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c70001917c2042d88f8a0449b99ca00a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_49cb67002f494deb925a5351464911d1","max":1355863,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8c5dcf88bcfa4db9bfc269adfde84cd8","value":1355863}},"cf2382dddd8d4f1f86bc9a64510d1a4b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7e383224d064b26be5ddcce796b59ac","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6e40b64fe808422faf2bf6c463770980","value":456318}},"d21823adc6194f3e9cf8a5ff991ae8c9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2e917a03c4d4a40b4e40acad78499a5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_32a5c61cf4cc46b8843cad58a93103c4","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_986f5d37e3c94c3993b29bb05423fb5c","value":898823}},"d883293c7dea4b99867b8069ded6f29d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0d615aa26884f1198c1d5e04cb1b15a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e324230bb1f74d859760659e24ab51aa":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e726209fb957474892fb1449f3bbaa79":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e80c023189ef48adb270d78a4aa85ab9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f65f4e5bc0834c02888c28fc39af3d18","placeholder":"","style":"IPY_MODEL_2994575ce3074b21938f0c0af1d9ce8c","value":"1.36M/1.36M[00:00&lt;00:00,30.3MB/s]"}},"e9d915f359cd4a1dabddcf6a3b7f4c3c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b74e8477ce344aa683c3ca66e0f96892","max":25,"min":0,"orientation":"horizontal","style":"IPY_MODEL_95b015ad6a5346829587144f698f49d9","value":25}},"eab5498835c04ca5b26b5b428c57f8f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa9491bed6d44773b8b6b18231a66adf","IPY_MODEL_c70001917c2042d88f8a0449b99ca00a","IPY_MODEL_e80c023189ef48adb270d78a4aa85ab9"],"layout":"IPY_MODEL_c1036d4817d54aae88261cc24dbdc38f"}},"ebb167e0250a4228b61940c1c9aaa78a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a0855e82ade4c59bdb558a537a13c50","IPY_MODEL_170b07d6b017429ca29447a77536b99f","IPY_MODEL_f23d8c7e18f04d228b8428307af1c35f"],"layout":"IPY_MODEL_bd66c1627fdd4777b39dcfe09481476a"}},"f23d8c7e18f04d228b8428307af1c35f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10d8af2471e24295b4b47485c1fe100f","placeholder":"","style":"IPY_MODEL_c04a275d19224fb5865faef75053466b","value":"499M/499M[00:02&lt;00:00,260MB/s]"}},"f5d760a291ce4599bd25e61b5d7ce0dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0d615aa26884f1198c1d5e04cb1b15a","placeholder":"","style":"IPY_MODEL_6e840885a5f043528594efdc24b39f6c","value":"481/481[00:00&lt;00:00,30.3kB/s]"}},"f65f4e5bc0834c02888c28fc39af3d18":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f99ec38dcb144da2966ce34048cce139":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa9491bed6d44773b8b6b18231a66adf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f99ec38dcb144da2966ce34048cce139","placeholder":"","style":"IPY_MODEL_253716178122452baf5b2df2e924f66d","value":"tokenizer.json:100%"}}}}},"nbformat":4,"nbformat_minor":5}